# R recap {#sec-P1}

Statistics can be divided into two broad categories: **descriptive statistics**, which describe or summarise data, and **inferential statistics**, which allow us to infer something about a population from a sample.

This session focuses on how to appropriately display and summarise data (i.e., descriptive stats). You should already be aware of several techniques for displaying data (e.g., bar charts, histograms, scatter plots). When and how to use these techniques is one focus of today.

There are two purposes for visualizing data.

First, the best way to get a 'gut' feel for your dataset is to look at it graphically. Examining data graphically enables you to identify any outliers (suspicious observations which could be errors). It will also help you to select the most appropriate inferential statistical model (more on this through the course).

Second, visualizations are used to impart information as clearly as possible to 'the reader', drawing attention to the most interesting aspects of your data. Graphics that are confusing, either through a lack of detail (e.g. no labels) or that contain too much information will fail in this central objective.

As you create graphics, keep in mind that they may be viewed on different machines, in grey scale, or by colour-blind or visually impaired readers. Colour scales such as those available from [ColorBrewer](https://colorbrewer2.org) or [viridis](https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html) are designed with this in mind.

It's best practice to load necessary packages at the top of your document. Today we'll use the *tidyverse* package, which is actually a collection of packages. First, you'll need to install it with `install.packages("tidyverse")`. Installation needs to be done once per machine, but loading is needed each time you re-open R.

```{r}
#| message: false
#| warning: false

library(tidyverse)
library(readxl) # installed with tidyverse, but not loaded in library(tidyverse)
set.seed(2025) # for fully reproducible code
```

------------------------------------------------------------------------

## Basic data exploration

### Object structure

We will mostly work with dataframes. A `data.frame` is a 2D rectangular object with columns and rows. In a tidy dataset, each row represents an 'observation' and each column represents a 'variable'. R (and often packages) contains several built-in dataframes.

The `data.frame` `cars` gives the max speed and stopping distance for cars built in the early 20th century. It is already available in your R session. We will use `cars` to demonstrate a few basic programming and statistical concepts.

```{r}
#| eval: false

# functions for basic details of objects
str(cars) # structure overview
class(cars) # object class
names(cars) # column names
head(cars) # first few rows
```

```{r}
head(cars, 2)
tail(cars, 2)
# what are the last 10 rows?
```

### Subsetting, renaming, and rearranging

There are several ways to access subsets of a `data.frame`:

-   Use `data_df$columnName` or `data_df[["columnName"]]` to extract a single column
-   Use `data_df[rows,columns]` to extract a block

```{r}
#| eval: false

cars$speed # whole column
cars[["speed"]] # whole column
```

```{r}
cars[1, 1] # row 1, column 1
cars[1:5, 1] # rows 1-5, column 1
cars[1:3, ] # leaving the 'columns' space blank returns all columns
```

We can also change column names. For illustration, let's make a copy of the `data.frame` to do that.

```{r}
cars2 <- cars 
names(cars2)
names(cars2)[1] <- "speed_mph" # change first column name
names(cars2)
names(cars2) <- c("speed_mph", "dist_ft") # change both column names
```

Rearranging and duplicating columns is also easy.

```{r}
head(cars2, 2)  
head(cars2[, 2:1], 2) # rearrange columns 

cars3 <- cars2[, c(2, 1, 1)] # duplicate a column
head(cars3, 2)
cars3 <- cars3[, 1:2] # remove the duplicated column
head(cars3, 2)
cars3$dist_x_speed <- cars3$dist_ft * cars3$speed_mph # create a new column
head(cars3, 2)
rm(cars3) # remove the dataframe 'cars3' from your R environment
```

::: callout-note
Recall that you must *assign* the results of an operation (`<-`) to save it. For example, running `cars2[, 2:1]` will display the results, but `cars2 <- cars2[, 2:1]` will *overwrite* `cars2` in your R environment.
:::

You can also subset based on criteria. Say we only want rows where the speed is $>$ 20 mph:

```{r}
cars_fast <- cars2[cars2$speed_mph > 20, ]
class(cars_fast) 
ncol(cars_fast)  # and how many *rows* are there?
head(cars_fast, 2)
```

### NAs and summary

When you import data, you should check for missing values. These are represented as `NA`.

We can check each element of a vector using `is.na()`, which will return `TRUE` if an element *is* `NA`, and `FALSE` if an element *is not* `NA`.

```{r}
#| eval: FALSE
#| echo: TRUE

is.na(cars2$speed_mph)
```

R converts logical values (i.e., `TRUE`/`FALSE`) to numeric (i.e., `1`/`0`) automatically. This is handy, but can be dangerous if you don't realize it.

```{r}
sum(is.na(cars2$speed_mph)) # how many are NA?
carsNA <- cars2
carsNA[c(2, 4, 5, 10), 1] <- NA
sum(is.na(carsNA$dist_ft))
```

Another very useful check is `summary()`:

```{r}
summary(cars)
```

```{r}
#| eval: FALSE
summary(carsNA)
```

Once you are confident that your `data.frame` looks sensible, that it contains the data you expect, and that you know what the data-types are, you can start to explore and summarise your data.

There are many graphical methods for data exploration. The appropriate method depends on the nature of the data and what you wish to communicate to the reader.

------------------------------------------------------------------------

## Graphical methods for displaying data

Always keep in mind that the primary reason for data visualization is to impart information concisely and accurately to your reader.

Graphics must be clear, concise and easy to understand. Brightspace contains some examples of bad graphics ('Learning resources\>Lecture support material\>Introduction (Lectures 1-3)\>Graphics').

![An example of a terrible graphic, as published in a Scottish government report.](figs/bad_fig_1.png){#fig-bad1}

In addition to poor design choices for effective communication (@fig-bad1), graphics can also be deliberately misleading (@fig-bad2).

![A misleading graphic. What type of plot is this and how is it misleading?](figs/bad_fig_2.png){#fig-bad2}

### Scatter plots

The scatter plot is used to plot two continuous variables against each other. It is commonly used for analyses like correlation or linear regression. The `plot()` function in R will create a scatter plot if given two numeric variables. There are two options for specifying the variables.

Using `data_df <- data.frame(x=1:3, y=4:6)`, the same plot can be created with either syntax:

```{r}
#| eval: false

plot(data_df$x, data_df$y) # two vectors: x, y
plot(y ~ x, data=data_df) # columns in dataframe: formula y ~ x
```

There are many options for modifying the output of `plot()`.

```{r}
#| label: fig-pch
#| fig-cap: "Symbol options."
#| fig-width: 6
#| fig-height: 2.5

par(mfrow=c(1,3)) # set the plot window to show 1 row, 3 columns

# plot(response ~ predictor, data=dataframe)
plot(dist_ft ~ speed_mph,
  data=cars2, xlab="Speed (mph)", ylab="Distance (ft)",
  main="Default symbol")
plot(dist_ft ~ speed_mph,
  data=cars2, xlab="Speed (mph)", ylab="Distance (ft)",
  pch=2, main="Setting 'pch=2'")
# you can check out more symbols and their respective numbers using this plot:
plot(1:20, pch=1:20, main="'pch' symbols 1 to 20")
```

```{r}
par(mfrow=c(1,1)) # reset to a single panel
```


::: Q.
With the `cars` dataset, plot stopping distance by speed for only those cars with a speed less than or equal to 15 mph.
:::

::: Q.
Use the `plot` help page to add an appropriate title to your plot.
:::

::: Q.
`?points` opens the help page for points. Search it for 'pch' and change the symbol in your plot.
:::

::: {.callout-tip collapse="true"}
## View solution
```{r}
#| eval: false

plot(dist ~ speed, data=cars[cars$speed <= 15, ], pch=2,
     xlab="Speed (mph)", ylab="Distance (ft)", 
     main="Cars with max speed <= 15 mph")
```
:::

```{r}
#| label: fig-speed_dist
#| fig-cap: "Stopping distance by speed."
#| fig-width: 3.5
#| fig-height: 4
#| echo: false

plot(dist ~ speed, data=cars[cars$speed <= 15, ], pch=2,
     xlab="Speed (mph)", ylab="Distance (ft)", 
     main="Cars with max speed <= 15 mph")
```

### Boxplots

Box plots are used to summarise a continuous variable by levels of a factor. We will use the `mtcars` dataset to illustrate this. You can learn about these data with `?mtcars`.

Explore the `data.frame` using the strategies covered above. Which variables are categorical? Which are continuous?

```{r}
head(mtcars, 2)
```

```{r}
#| label: fig-mpl_cyl
#| fig-cap: "Boxplot showing miles per litre vs. number of carburetors"
#| fig-width: 4
#| fig-height: 4
#| echo: FALSE

mtcars2 <- mtcars
mtcars2$mpl <- mtcars2$mpg / 4.5
boxplot(mpl ~ cyl, data=mtcars2, xlab="Cylinders", ylab="Miles per litre")
```

```{r}
#| eval: FALSE

?boxplot
# See examples at bottom of the help page
```

::: Q.
Reproduce the plot shown in @fig-mpl_cyl (assume 1 gallon = 4.5 L). You will need to generate a new variable (miles per litre) and label your box plot appropriately. You can limit the extent of the y-axis by adding the argument `ylim=c(a, b)` where `a` and `b` are the limits you want (e.g., `ylim=c(0, 100)`).
:::

::: {.callout-tip collapse="true"}
## View solution
```{r}
#| eval: false
mtcars2 <- mtcars
mtcars2$mpl <- mtcars2$mpg / 4.5

boxplot(mpl ~ cyl, data=mtcars2, xlab="Cylinders", ylab="Miles per litre")
```
:::

::: Q.
Use `?boxplot` to investigate what the box and whiskers actually represent.
:::

Note that box plots are not the most visually intuitive. Packages like `ggplot2` (and extensions) make alternatives like those in @fig-mpl_cyl_ggplot simple to produce. We will cover some of these later.

```{r}
#| label: fig-mpl_cyl_ggplot
#| fig-cap: "Alternatives to boxplots"
#| fig-width: 10
#| fig-height: 4
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

library(ggdist); library(cowplot)
theme_set(theme_classic())
mtcars2$cyl <- factor(mtcars2$cyl)
mtcars_mns <- mtcars2 |>
  group_by(cyl) |>
  summarise(mpl_mn=mean(mpl),
            mpl_se=sd(mpl)/sqrt(n()))
p_a <- ggplot(mtcars2, aes(cyl)) + 
  geom_jitter(aes(y=mpl), alpha=0.5, width=0.05, size=1.5, shape=1) + 
  geom_errorbar(data=mtcars_mns, aes(ymin=mpl_mn-2*mpl_se, ymax=mpl_mn+2*mpl_se), width=0.1) +
  geom_point(data=mtcars_mns, aes(y=mpl_mn), size=2) +
  labs(subtitle="Strip plot with means and 2 standard errors",
       x="Cylinders", y="Miles per litre")
p_b <- ggplot(mtcars2, aes(mpl, cyl)) + 
  geom_dots(side="bottom", scale=0.5) +
  stat_halfeye(scale=0.5, .width=c(0.5, 0.95)) + 
  labs(subtitle="Rain cloud plot showing median with middle 50% and 95%",
       y="Cylinders", x="Miles per litre")
plot_grid(p_a, p_b, align="hv", axis="tblr", nrow=1)
```

### Line plots

Line plots are most often seen in timeseries plots with time on the x-axis and the response on the y-axis. Line plots involve joining points with a line, which indicates that you have made assumptions about the value of the response variable between successive measurements.

We will examine these plots using the dataset `lynx`, which consists of the number of Canadian lynx pelts sold per year between 1821 - 1934. It is a 'classic' dataset as it shows a cyclical 'boom-and-bust' lynx population (demonstrating predator-prey interactions).

First, we will create a variable `Year`.

```{r}
str(lynx)
```

```{r}
#| results: "hide"

str(lynx)
lynx2 <- as.data.frame(lynx) 
str(lynx2) 
lynx2$Year <- seq(from=1821, to=1934, by=1)
lynx2$Trappings <- as.numeric(lynx2$x) # Time-Series is complicated.
str(lynx2)
head(lynx2, 2) 
```

In R, we use *functions* to perform actions on *objects*. Functions have arguments, taking the form `functionName(arg1=..., arg2=...)`. If you do not name the arguments, the function will assume that you are listing the arguments in order. See the help file for a function with `?` to see the argument order (e.g., `?seq`).

::: Q.
Using `seq()`, write a piece of code which generates odd numbers between 1 and 20. Try with and without naming the arguments.
:::

::: {.callout-tip collapse="true"}
## View solution
```{r}
#| eval: false
seq(from=1, to=20, by=2)
seq(1, 20, 2)
```
:::

Use `?plot` to investigate options for plotting. Find the `type=` argument for plotting both the points and a connecting line. Why might this be the best option here?

::: Q.
Using `plot()`, produce a line plot similar to @fig-lynx_1.
:::

```{r}
#| label: fig-lynx_1
#| fig-cap: "The number of lynx trapped in Canada (1820-1934)"
#| echo: false
#| fig-align: 'center'

plot(Trappings ~ Year, data=lynx2, pch=19,
     main="Lynx trapping in Canada (1820-1934)", type="b")
```

::: {.callout-tip collapse="true"}
## View solution
```{r}
#| eval: false
plot(Trappings ~ Year, data=lynx2, pch=19,
     main="Lynx trapping in Canada (1820-1934)", type="b")
```
:::

::: Q.
Create a plot that shows the log number of trappings from 1850 to 1900.
:::

::: {.callout-tip collapse="true"}
## View solution
```{r}
#| eval: false
plot(log(Trappings) ~ Year, 
     data=lynx2[lynx2$Year >= 1850 & lynx2$Year <= 1900, ], 
     pch=19,
     main="Lynx trapping in Canada (1820-1934)", type="b")
```
:::


### Histograms

Histograms illustrate the distribution of **continuous** data. In histograms the bars are adjacent (no gap). This indicates that the underlying values are continuous rather than discrete.

```{r}
#| label: fig-lynx_hist_default
#| fig-cap: "Lynx pelts per year with default settings."
#| fig-width: 4
#| fig-height: 3

hist(lynx2$Trappings, main="Lynx trapping", xlab="Trapped lynx per year")
```

::: Q.
What conclusions do you draw from this plot? Which range of values was most common across years?
:::

Be aware that histograms can be quite sensitive to the number of bins, and you should explore different options. You can set the number or values of break points with `breaks=...`.

```{r}
#| label: fig-lynx_hist_b1
#| fig-cap: "Lynx pelts per year with breaks=5 (left) and a vector of breaks (right)."
#| fig-width: 6
#| fig-height: 3

par(mfrow=c(1,2)) # panels for the plotting window
# R takes the number of breaks as a suggestion
hist(lynx2$Trappings, xlab="Trapped lynx per year",
     breaks=5)
# this forces R to plot according to the defined breaks
hist(lynx2$Trappings, xlab="Trapped lynx per year",
     breaks=c(0, 500, 1000, 2000, 5000, 10000))
```

```{r}
#| label: fig-lynx_hist_panels
#| fig-cap: "Histograms of lynx pelts per year with different breaks"
#| fig-width: 6
#| fig-height: 4
#| code-fold: true

par(mfrow=c(2, 2)) # plot panels (2 rows x 2 columns)
par(mar=rep(2, 4)) # change the plot margins
hist(lynx2$Trappings, main="bin width: 100", xlab="Trapped lynx per year", 
     breaks=seq(0, 10000, by=100))
hist(lynx2$Trappings, main="bin width: 500", xlab="Trapped lynx per year", 
     breaks=seq(0, 10000, by=500))
hist(lynx2$Trappings, main="bin width: 1000", xlab="Trapped lynx per year", 
     breaks=seq(0, 10000, by=1000))
hist(lynx2$Trappings, main="bin width: 2000", xlab="Trapped lynx per year", 
     breaks=seq(0, 10000, by=2000))
```

```{r}
par(mfrow=c(1, 1)) # reset the par setting.
```

Which of these plots is the most useful? There is no definitive answer, but the first is very busy and the last fails to show relevant detail near 0. Bin widths of 500-1000 communicate the patterns most clearly.

Generally, 5-15 breaks usually work well.

### Bar graphs

Bar graphs are used to plot counts of categorical or discrete variables. We'll be using the `islands` dataset which is a named vector of island areas.

::: callout-note
Many objects in R can have row names. However, converting between data types may lose this information. Consequently, **it is better practice to store relevant information in a column**. Nevertheless, there are occasions where this is useful and you may come across datasets with data stored as row names.
:::

Working with data involves a lot of time spent tidying the datasets: cleaning, checking, and reshaping into useful formats. We will cover a more modern set of methods for this later in the course using the *tidyverse* package. For now, we'll stay with base R. First, we need to tidy the `islands` data.

```{r}
#| results: "hide"

str(islands) 
class(islands) # this is a named numeric vector
head(islands)

# convert to a dataframe
islands_df <- as.data.frame(islands) 
head(islands_df, 2)
str(islands_df) # rownames are not shown!
```

```{r}
# put the row names into a new column
islands_df$LandMass <- row.names(islands_df) 
head(islands_df, 2)

# set row names to the row number
row.names(islands_df) <- 1:nrow(islands_df) 
names(islands_df)[1] <- "Area" 
head(islands_df, 2) 

# reorder by area
islands_df <- islands_df[order(islands_df$Area, decreasing=TRUE), ]
head(islands_df, 3)
```

We can use the function `barplot()` to plot the vector of island areas.

```{r}
#| label: fig-island_1
#| fig-cap: "Island areas with barplot defaults"
#| fig-width: 6
#| fig-height: 2.5

par(mar=c(4, 0, 0, 0)) # change the margin sizes
barplot(islands_df$Area)
```

The whole dataset includes a lot of very small areas, so let's cut it down to just the 10 largest. Since the dataset is already sorted, we can take rows `1:10`.

```{r}
#| label: fig-island_2
#| fig-cap: "Top 10 island areas"
#| fig-width: 4
#| fig-height: 4

barplot(islands_df$Area[1:10])
```

And the next step is to add some names to the x-axis...

```{r}
#| label: fig-island_3
#| fig-cap: "Top 10 island areas with names"
#| fig-width: 4
#| fig-height: 4

barplot(islands_df$Area[1:10], names=islands_df$LandMass[1:10])
```

Which of course are unreadable. There are many options here (e.g., see `las` in `?par`) but we will rotate the plot. To do this, we need to re-adjust the margins, set `horiz=TRUE` and `las=1`, and use `[10:1]` so the largest is on top.

```{r}
#| label: fig-island_4
#| fig-cap: "Finally! Did you know Antarctica is bigger than Europe?"
#| fig-width: 4
#| fig-height: 4

par(mar=c(4, 10, 0, 0))
barplot(islands_df$Area[10:1], names=islands_df$LandMass[10:1], 
        horiz=TRUE, las=1, xlab="Area (km2)")
```

Data visualization is an iterative process with lots of trial and error to find a plot that communicates the message within the data well. There are several packages (e.g., *ggplot2*) that make these sort of adjustments and explorations less opaque than all of the options in `par()`.

::: callout-note
We will cover *ggplot2* and other the *tidyverse* packages in more detail soon. You are welcome to use whichever system you prefer.
:::

------------------------------------------------------------------------

## Summary statistics

You will often need to summarise your data before you present it. Data summaries are usually contained in tables and they can sometimes replace graphics (e.g., where the data is relatively simple or where individual precise values are important). There are many types of summary statistics. Here we are concerned with central tendency and variability.

::: Q.
What are the three main measures of central tendency?
:::

::: Q.
What are three measures of variability?
:::

The most appropriate metrics of central tendency or variability will depend on your data. Another summary statistic that you might include is sample size. R is very good at producing summary statistics, and there are myriad ways to produce them. We'll return to the `cars2` dataset.

```{r}
summary(cars2) 
```

```{r}
#| eval: FALSE

summary(cars2[cars2$speed_mph > 20, ]) 
```

```{r}
#| eval: FALSE

# Recall the options to access a column in a dataframe
summary(cars2$speed_mph) 
summary(cars2[, 1])
summary(cars2[, "speed_mph"])
```

Often you'll wish to summarise your data across levels of a certain factor, such as levels of a certain treatment. More complex summaries can be made using the *dplyr* package. We'll go into more detail later on some of the very powerful ways this package (and others in the *tidyverse*) can be used.

We'll use the built-in dataset `InsectSprays`. Viewing your raw data can be an important check as well. You can open a spreadsheet-style viewer in R using `View(YourDataFrame)`.

```{r}
str(InsectSprays)
glimpse(InsectSprays) # glimpse() is loaded with tidyverse
```

```{r}
#| eval: FALSE

# spray is the categorical predictor; count is the response
View(InsectSprays)
```

To do more complex summaries, we will string together a series of functions. This can be done in a nested format (e.g., `fun3(fun2(fun1(dataset)))`), but this gets unwieldy very quickly.

So, let's use the *pipe* operator `|>`. This takes the output from one function and feeds it as the first input of the next (e.g., `dataset |> fun1() |> fun2() |> fun3()`), making code much more legible. Many functions in the *tidyverse* are built for piping.

```{r}
#| eval: FALSE

?`|>`
```

```{r}
#| results: "hide"

# use group_by() with the grouping column name(s)
spray_summaries <- InsectSprays |>
  group_by(spray) |>
  summarise(count_mean=mean(count))
spray_summaries
```

```{r}
# it is very easy to calculate any number of summary statistics
InsectSprays |>
  group_by(spray) |>
  summarise(mean=mean(count) |> signif(3),
            median=median(count),
            max=max(count),
            sd=sd(count) |> signif(3),
            N=n(),
            N_over_10=sum(count > 10),
            Pr_over_5=mean(count > 5))
```

### Choosing a central tendency metric

The choice of central tendency metric depends on the nature of the data and objectives of your research. We will use datasets that you downloaded from Brightspace (Practicals \> data). Remember to put these into the *data* folder in your working directory (or modify the file paths in the code accordingly).

```{r}
# this will load the 'Scallop %fat' data sheet from the xlsx spreadsheet.
scallop_df <- read_excel("data/H2DS_practicalData.xlsx", sheet="Scallop %fat")
str(scallop_df)
# avoid spaces and symbols in column names. It's a pain.
names(scallop_df) <- "fat_pct"
```

::: Q.
Check the data using the methods above. Does it look OK to you?
:::

::: Q.
Are these data likely to be continuous or discontinuous?
:::

::: Q.
Create a plot to visualize the distribution of these data.
:::

::: Q.
Do you spot any issues?
:::

::: {.callout-tip collapse="true"}
## View solution
```{r}
#| label: fig-scallop_hist
#| fig-cap: "Histogram of fat percentage."
#| fig-width: 4
#| fig-height: 4

hist(scallop_df$fat_pct, main=NULL) # (what does 'main=NULL' do?)
```
:::

You should have spotted a potential outlier. Data entry errors are common, and a check against the original data sheet shows that the decimal was typed in the wrong place. The following code helps you locate the error.

```{r}
which(scallop_df$fat_pct > 50) # which() returns the indexes
scallop_df$fat_pct[35:37] # row 36 is 99.0, but should be 9.90
scallop_df <- scallop_df[, c(1, 1)] # duplicate column
names(scallop_df) <- c("fat_pct_orig", "fat_pct_corr")
head(scallop_df, 2)
```

```{r}
#| results: "hide"

# there are many ways to 'fix' the outlier in R.
# You need to correct the outlier in row 36 of column 'fat_pct_corr'
scallop_df$fat_pct_corr[36] <- 9.9
which(scallop_df$fat_pct_corr > 90) 
# integer(0) - this means that no elements in fat_pct_corr contain values >90
```

Now summarise `scallop_df` using some of the methods above.

::: Q.
Create a histogram for the corrected column. How does it differ from the original column with the error?
:::

::: Q.
Calculate mean, variance, median, interquartile range, minimum, maximum and range for both fat_pct_orig and fat_pct_corr.
:::

::: Q.
Suppose the outlier was even bigger (i.e. your typo was even worse). Adjust your data, multiplying the erroneous data item by 10; copy the `fat_pct_orig` column and change row 36 to 999.
:::

::: Q.
Calculate the same summary statistics.
:::

::: Q.
Which measures of central tendency and variability are most 'robust' against this outlier?
:::

Or look individually instead of calculating many metrics at once with `dplyr` functions:

```{r}
summary(scallop_df$fat_pct_corr)
var(scallop_df$fat_pct_corr)
IQR(scallop_df$fat_pct_corr)
```

R is excellent at generating well formatted tables such as shown in @tbl-scallop. What is missing from from this table?

```{r}
#| label: tbl-scallop
#| tbl-cap: "Summary statistics with and without an outlier. Note which summary stats are most influenced by the outlier."
#| echo: false

scallop_df |>
  pivot_longer(1:2, names_to="Column", values_to="val") |>
  group_by(Column) |>
  summarise(Mean=mean(val) |> signif(3),
            Median=median(val) |> signif(3),
            `Standard deviation`=sd(val) |> signif(3),
            Range=range(val) |> diff() |> signif(3),
            `Interquartile range`=IQR(val) |> signif(3)) |>
  knitr::kable(booktabs=TRUE, digits=3)
```

::: Q.
How would the patterns seen in @tbl-scallop influence your choice if you were required to summarise data that you thought might contain values that could be erroneous? Consider how each metric is influenced by the data distribution and by outliers.
:::

Let's load a dataset that gives the length of hake across three years of sampling.

```{r}
hake_df <- read_excel("data/H2DS_practicalData.xlsx", sheet="Hake")
str(hake_df) # once again, column names made for excel rather than R
```

::: Q.
What type of variable is `length`?
:::

::: Q.
Select an appropriate graphical method and display these data.
:::

::: Q.
In your own time, use the `dplyr` functions to summarise the hake data by year.
:::

```{r}
hake_df$Year <- as.factor(hake_df$Year) # Treat as categorical, not numeric
names(hake_df) <- c("Year", "Length") # simplify the column names
```

```{r}
#| label: tbl-hake
#| tbl-cap: "Summary of hake data."
#| echo: false

hake_df |>
  group_by(Year) |>
  summarise(`Mean length (cm)`=mean(Length)) |>
  knitr::kable(booktabs=TRUE, digits=1)
```

The following 'settling velocity' data relates to the settling velocity of salmon faecal material. Shona Magill generated these data.

```{r}
fishPoo_df <- read_excel("data/H2DS_practicalData.xlsx", sheet="Settling velocity")
str(fishPoo_df)
```

::: Q.
Produce a histogram of the settling velocity. Is it left or right skewed?
:::

::: Q.
Which measures of central tendency and variability are most appropriate?
:::

::: Q.
Sketch the distribution and indicate the relative positions of the mean and median.
:::

::: Q.
Generate a new column of the log-transformed settling velocity data and plot these data.
:::

::: Q.
What measures of central tendency and variability could be applied to the log-transformed data? Selecting the preferable metrics for a dataset is not necessarily straightforward.
:::

@tbl-metric gives some indication of what issues you might consider.

```{r}
#| label: tbl-metric
#| tbl-cap: "Appropriate measures of central tendency and variability according to the underlying data distribution."
#| echo: false

tibble(a=c("Continuous, unimodal, symmetric", "Continuous, skewed", 
           "Continuous, multimodal", "Discontinuous"),
       b=c("Mean", "Median", 
           "None; state modes", "None; data-dependent"),
       c=c("Variance or sd", "Interquartile range", 
           "None; summarise by group", "Range?")) |>
  # mutate(across(where(is.character), ~str_wrap(.x, 20))) |>
  rename(`Data distribution`=a, 
         `Central tendency metric`=b,
         `Variability metric`=c) |>
  knitr::kable(booktabs=T) 
```

------------------------------------------------------------------------

## Conclusions

Visualizing and summarising data are the critical first steps in the data analysis and reporting workflow. We use graphical methods to firstly explore our own data. Once we have made sense of it we select the most appropriate method to convey that understanding to our readers. We may help that communication by summarising data in the most appropriate way taking into account the distribution of the data and the presence of outliers.
