{
  "hash": "8a12c5620a5f20c6ac872b3f10daf8f7",
  "result": {
    "engine": "knitr",
    "markdown": "# R recap {#sec-P1}\n\nStatistics can be divided into two broad categories: 1) descriptive statistics, which describe or summarise data, and 2) inferential statistics, which allow us to infer something about a population from a sample.\n\nThis session focuses on how to appropriately display and summarise data (i.e., descriptive stats). You should already be aware of several techniques for displaying data (e.g., bar charts, histograms, scatter plots). When and how to use these techniques is one focus of today.\n\nThere are two purposes for visualizing data.\n\nFirst, the best way to get a 'gut' feel for your dataset is to look at it graphically. Examining data graphically enables you to identify any outliers (suspicious observations which could be errors). It will also help you to select the most appropriate inferential statistical model (more on this through the course).\n\nSecond, visualizations are used to impart information as clearly as possible to 'the reader', drawing attention to the most interesting aspects of your data. Graphics that are confusing, either through a lack of detail (e.g. no labels) or that contain too much information will fail in this central objective.\n\nAs you create graphics, keep in mind that they may be viewed on different machines, in grey scale, or by colour-blind or visually impaired readers. Colour scales such as those available from [ColorBrewer](https://colorbrewer2.org) or [viridis](https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html) are designed with this in mind.\n\nIt's best practice to load necessary packages at the top of your document. Today we'll use the *tidyverse* package, which is actually a collection of packages. First, you'll need to install it with `install.packages(\"tidyverse\")`. Installation needs to be done once per machine, but loading is needed each time you re-open R.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl) # installed with tidyverse, but not loaded in library(tidyverse)\nset.seed(2025) # for fully reproducible code\n```\n:::\n\n\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n## Basic data exploration\n\n### Object structure\n\nWe will mostly work with dataframes. A `data.frame` is a 2D rectangular object with columns and rows. In a tidy dataset, each row represents an 'observation' and each column represents a 'variable'. R (and often packages) contains several built-in dataframes.\n\nThe `data.frame` `cars` gives the max speed and stopping distance for cars built in the early 20th century. It is already available in your R session. We will use `cars` to demonstrate a few basic programming and statistical concepts.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# functions for basic details of objects\nstr(cars) # structure overview\nclass(cars) # object class\nnames(cars) # column names\nhead(cars) # first few rows\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(cars, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  speed dist\n1     4    2\n2     4   10\n```\n\n\n:::\n\n```{.r .cell-code}\ntail(cars, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   speed dist\n49    24  120\n50    25   85\n```\n\n\n:::\n\n```{.r .cell-code}\n# what are the last 10 rows?\n```\n:::\n\n\n\n\n\n\n\n\n### Subsetting, renaming, and rearranging\n\nThere are several ways to access subsets of a `data.frame`:\n\n-   Use `data_df$columnName` or `data_df[[\"columnName\"]]` to extract a single column\n-   Use `data_df[rows,columns]` to extract a block\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncars$speed # whole column\ncars[[\"speed\"]] # whole column\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncars[1, 1] # row 1, column 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n```{.r .cell-code}\ncars[1:5, 1] # rows 1-5, column 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4 4 7 7 8\n```\n\n\n:::\n\n```{.r .cell-code}\ncars[1:3, ] # leaving the 'columns' space blank returns all columns\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  speed dist\n1     4    2\n2     4   10\n3     7    4\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\nWe can also change column names. For illustration, let's make a copy of the `data.frame` to do that.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncars2 <- cars \nnames(cars2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"speed\" \"dist\" \n```\n\n\n:::\n\n```{.r .cell-code}\nnames(cars2)[1] <- \"speed_mph\" # change first column name\nnames(cars2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"speed_mph\" \"dist\"     \n```\n\n\n:::\n\n```{.r .cell-code}\nnames(cars2) <- c(\"speed_mph\", \"dist_ft\") # change both column names\n```\n:::\n\n\n\n\n\n\n\n\nRearranging and duplicating columns is also easy.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(cars2, 2)  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  speed_mph dist_ft\n1         4       2\n2         4      10\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(cars2[, 2:1], 2) # rearrange columns \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  dist_ft speed_mph\n1       2         4\n2      10         4\n```\n\n\n:::\n\n```{.r .cell-code}\ncars3 <- cars2[, c(2, 1, 1)] # duplicate a column\nhead(cars3, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  dist_ft speed_mph speed_mph.1\n1       2         4           4\n2      10         4           4\n```\n\n\n:::\n\n```{.r .cell-code}\ncars3 <- cars3[, 1:2] # remove the duplicated column\nhead(cars3, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  dist_ft speed_mph\n1       2         4\n2      10         4\n```\n\n\n:::\n\n```{.r .cell-code}\ncars3$dist_x_speed <- cars3$dist_ft * cars3$speed_mph # create a new column\nhead(cars3, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  dist_ft speed_mph dist_x_speed\n1       2         4            8\n2      10         4           40\n```\n\n\n:::\n\n```{.r .cell-code}\nrm(cars3) # remove the dataframe 'cars3' from your R environment\n```\n:::\n\n\n\n\n\n\n\n\n::: callout-note\nRecall that you must *assign* the results of an operation (`<-`) to save it. For example, running `cars2[, 2:1]` will display the results, but `cars2 <- cars2[, 2:1]` will *overwrite* `cars2` in your R environment.\n:::\n\nYou can also subset based on criteria. Say we only want rows where the speed is $>$ 20 mph:\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncars_fast <- cars2[cars2$speed_mph > 20, ]\nclass(cars_fast) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"data.frame\"\n```\n\n\n:::\n\n```{.r .cell-code}\nncol(cars_fast)  # and how many *rows* are there?\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(cars_fast, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   speed_mph dist_ft\n44        22      66\n45        23      54\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n### NAs and summary\n\nWhen you import data, you should check for missing values. These are represented as `NA`.\n\nWe can check each element of a vector using `is.na()`, which will return `TRUE` if an element *is* `NA`, and `FALSE` if an element *is not* `NA`.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nis.na(cars2$speed_mph)\n```\n:::\n\n\n\n\n\n\n\n\nR converts logical values (i.e., `TRUE`/`FALSE`) to numeric (i.e., `1`/`0`) automatically. This is handy, but can be dangerous if you don't realize it.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(cars2$speed_mph)) # how many are NA?\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n\n```{.r .cell-code}\ncarsNA <- cars2\ncarsNA[c(2, 4, 5, 10), 1] <- NA\nsum(is.na(carsNA$dist_ft))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\nAnother very useful check is `summary()`:\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(cars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(carsNA)\n```\n:::\n\n\n\n\n\n\n\n\nOnce you are confident that your `data.frame` looks sensible, that it contains the data you expect, and that you know what the data-types are, you can start to explore and summarise your data.\n\nThere are many graphical methods for data exploration. The appropriate method depends on the nature of the data and what you wish to communicate to the reader.\n\n------------------------------------------------------------------------\n\n## Graphical methods for displaying data\n\nAlways keep in mind that the primary reason for data visualization is to impart information concisely and accurately to your reader.\n\nGraphics must be clear, concise and easy to understand. Brightspace contains some examples of bad graphics ('Learning resources\\>Lecture support material\\>Introduction (Lectures 1-3)\\>Graphics').\n\n![An example of a terrible graphic, as published in a Scottish government report.](figs/bad_fig_1.png){#fig-bad1}\n\nIn addition to poor design choices for effective communication (@fig-bad1), graphics can also be deliberately misleading (@fig-bad2).\n\n![A misleading graphic. What type of plot is this and how is it misleading?](figs/bad_fig_2.png){#fig-bad2}\n\n### Scatter plots\n\nThe scatter plot is used to plot two continuous variables against each other. It is commonly used for analyses like correlation or linear regression.\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Symbol options.](P1_R_recap_files/figure-pdf/fig-pch-1.pdf){#fig-pch}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n\n::: Q.\nUse the `plot` help page to add an appropriate title to your plot.\n:::\n\n::: Q.\n`?points` opens the help page for points. Search it for 'pch' and change the symbol in your plot.\n:::\n\n::: Q.\nWith the `cars` dataset, plot stopping distance by speed for only those cars with a speed less than or equal to 15 mph.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## View solution\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(dist ~ speed, data=cars[cars$speed <= 15, ], pch=2,\n     xlab=\"Speed (mph)\", ylab=\"Distance (ft)\", \n     main=\"Cars with max speed <= 15 mph\")\n```\n:::\n\n\n\n\n\n\n\n:::\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Stopping distance by speed.](P1_R_recap_files/figure-pdf/fig-speed_dist-1.pdf){#fig-speed_dist}\n:::\n:::\n\n\n\n\n\n\n\n\n### Boxplots\n\nBox plots are used to summarise a continuous variable by levels of a factor. We will use the `mtcars` dataset to illustrate this. You can learn about these data with `?mtcars`.\n\nExplore the `data.frame` using the strategies covered above. Which variables are categorical? Which are continuous?\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(mtcars, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21   6  160 110  3.9 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21   6  160 110  3.9 2.875 17.02  0  1    4    4\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Boxplot showing miles per litre vs. number of carburetors](P1_R_recap_files/figure-pdf/fig-mpl_cyl-1.pdf){#fig-mpl_cyl}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n?boxplot\n# See examples at bottom of the help page\n# Produce a box plot with axes labels and a title\n```\n:::\n\n\n\n\n\n\n\n\n::: Q.\nReproduce the plot shown in @fig-mpl_cyl (assume 1 gallon = 4.5 L). You will need to generate a new variable (miles per litre) and label your box plot appropriately. You can limit the extent of the y-axis by adding the argument `ylim=c(a, b)` where `a` and `b` are the limits you want (e.g., `ylim=c(0, 100)`).\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## View solution\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars2 <- mtcars\nmtcars2$mpl <- mtcars2$mpg / 4.5\n\nboxplot(mpl ~ cyl, data=mtcars2, xlab=\"Cylinders\", ylab=\"Miles per litre\")\n```\n:::\n\n\n\n\n\n\n\n:::\n\n::: Q.\nUse `?boxplot` to investigate what the box and whiskers actually represent.\n:::\n\nNote that box plots are not the most visually intuitive. Packages like `ggplot2` (and extensions) make alternatives like those in @fig-mpl_cyl_ggplot simple to produce. We will cover some of these later.\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Alternatives to boxplots](P1_R_recap_files/figure-pdf/fig-mpl_cyl_ggplot-1.pdf){#fig-mpl_cyl_ggplot}\n:::\n:::\n\n\n\n\n\n\n\n\n### Line plots\n\nLine plots are most often seen in timeseries plots with time on the x-axis and the response on the y-axis. Line plots involve joining points with a line, which indicates that you have made assumptions about the value of the response variable between successive measurements.\n\nWe will examine these plots using the dataset `lynx`, which consists of the number of Canadian lynx pelts sold per year between 1821 - 1934. It is a 'classic' dataset as it shows a cyclical 'boom-and-bust' lynx population (demonstrating predator-prey interactions).\n\nFirst, we will create a variable `Year`.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(lynx)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Time-Series [1:114] from 1821 to 1934: 269 321 585 871 1475 ...\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(lynx)\nlynx2 <- as.data.frame(lynx) \nstr(lynx2) \nlynx2$Year <- seq(from=1821, to=1934, by=1)\nlynx2$Trappings <- as.numeric(lynx2$x) # Time-Series is complicated.\nstr(lynx2)\nhead(lynx2, 2) \n```\n:::\n\n\n\n\n\n\n\n\nIn R, we use *functions* to perform actions on *objects*. Functions have arguments, taking the form `functionName(arg1=..., arg2=...)`. If you do not name the arguments, the function will assume that you are listing the arguments in order. See the help file for a function with `?` to see the argument order (e.g., `?seq`).\n\n::: Q.\nUsing `seq()`, write a piece of code which generates odd numbers between 1 and 20. Try with and without naming the arguments.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## View solution\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseq(from=1, to=20, by=2)\nseq(1, 20, 2)\n```\n:::\n\n\n\n\n\n\n\n:::\n\nUse `?plot` to investigate options for plotting. Find the `type=` argument for plotting both the points and a connecting line. Why might this be the best option here?\n\n::: Q.\nUsing `plot()`, produce a line plot similar to @fig-lynx_1.\n:::\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![The number of lynx trapped in Canada (1820-1934)](P1_R_recap_files/figure-pdf/fig-lynx_1-1.pdf){#fig-lynx_1 fig-align='center'}\n:::\n:::\n\n\n\n\n\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## View solution\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(Trappings ~ Year, data=lynx2, pch=19,\n     main=\"Lynx trapping in Canada (1820-1934)\", type=\"b\")\n```\n:::\n\n\n\n\n\n\n\n:::\n\n::: Q.\nCreate a plot that shows the log number of trappings from 1850 to 1900.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## View solution\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(log(Trappings) ~ Year, \n     data=lynx2[lynx2$Year >= 1850 & lynx2$Year <= 1900, ], \n     pch=19,\n     main=\"Lynx trapping in Canada (1820-1934)\", type=\"b\")\n```\n:::\n\n\n\n\n\n\n\n:::\n\n\n### Histograms\n\nHistograms illustrate the distribution of **continuous** data. In histograms the bars are adjacent (no gap). This indicates that the underlying values are continuous rather than discrete.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(lynx2$Trappings, main=\"Lynx trapping\", xlab=\"Trapped lynx per year\")\n```\n\n::: {.cell-output-display}\n![Lynx pelts per year with default settings.](P1_R_recap_files/figure-pdf/fig-lynx_hist_default-1.pdf){#fig-lynx_hist_default fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n::: Q.\nWhat conclusions do you draw from this plot? Which range of values was most common across years?\n:::\n\nBe aware that histograms can be quite sensitive to the number of bins, and you should explore different options. You can set the number or values of break points with `breaks=...`.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,2)) # panels for the plotting window\n# R takes the number of breaks as a suggestion\nhist(lynx2$Trappings, xlab=\"Trapped lynx per year\",\n     breaks=5)\n# this forces R to plot according to the defined breaks\nhist(lynx2$Trappings, xlab=\"Trapped lynx per year\",\n     breaks=c(0, 500, 1000, 2000, 5000, 10000))\n```\n\n::: {.cell-output-display}\n![Lynx pelts per year with breaks=5 (left) and a vector of breaks (right).](P1_R_recap_files/figure-pdf/fig-lynx_hist_b1-1.pdf){#fig-lynx_hist_b1 fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npar(mfrow=c(2, 2)) # plot panels (2 rows x 2 columns)\npar(mar=rep(2, 4)) # change the plot margins\nhist(lynx2$Trappings, main=\"bin width: 100\", xlab=\"Trapped lynx per year\", \n     breaks=seq(0, 10000, by=100))\nhist(lynx2$Trappings, main=\"bin width: 500\", xlab=\"Trapped lynx per year\", \n     breaks=seq(0, 10000, by=500))\nhist(lynx2$Trappings, main=\"bin width: 1000\", xlab=\"Trapped lynx per year\", \n     breaks=seq(0, 10000, by=1000))\nhist(lynx2$Trappings, main=\"bin width: 2000\", xlab=\"Trapped lynx per year\", \n     breaks=seq(0, 10000, by=2000))\n```\n\n::: {.cell-output-display}\n![Histograms of lynx pelts per year with different breaks](P1_R_recap_files/figure-pdf/fig-lynx_hist_panels-1.pdf){#fig-lynx_hist_panels fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1, 1)) # reset the par setting.\n```\n:::\n\n\n\n\n\n\n\n\nWhich of these plots is the most useful? There is no definitive answer, but the first is very busy and the last fails to show relevant detail near 0. Bin widths of 500-1000 communicate the patterns most clearly.\n\nGenerally, 5-15 breaks usually work well.\n\n### Bar graphs\n\nBar graphs are used to plot counts of categorical or discrete variables. We'll be using the `islands` dataset which is a named vector of island areas.\n\n::: callout-note\nMany objects in R can have row names. However, converting between data types may lose this information. Consequently, **it is better practice to store relevant information in a column**. Nevertheless, there are occasions where this is useful and you may come across datasets with data stored as row names.\n:::\n\nWorking with data involves a lot of time spent tidying the datasets: cleaning, checking, and reshaping into useful formats. We will cover a more modern set of methods for this later in the course using the *tidyverse* package. For now, we'll stay with base R. First, we need to tidy the `islands` data.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(islands) \nclass(islands) # this is a named numeric vector\nhead(islands)\n\n# convert to a dataframe\nislands_df <- as.data.frame(islands) \nhead(islands_df, 2)\nstr(islands_df) # rownames are not shown!\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# put the row names into a new column\nislands_df$LandMass <- row.names(islands_df) \nhead(islands_df, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           islands   LandMass\nAfrica       11506     Africa\nAntarctica    5500 Antarctica\n```\n\n\n:::\n\n```{.r .cell-code}\n# set row names to the row number\nrow.names(islands_df) <- 1:nrow(islands_df) \nnames(islands_df)[1] <- \"Area\" \nhead(islands_df, 2) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Area   LandMass\n1 11506     Africa\n2  5500 Antarctica\n```\n\n\n:::\n\n```{.r .cell-code}\n# reorder by area\nislands_df <- islands_df[order(islands_df$Area, decreasing=TRUE), ]\nhead(islands_df, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Area      LandMass\n3  16988          Asia\n1  11506        Africa\n35  9390 North America\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\nWe can use the function `barplot()` to plot the vector of island areas.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mar=c(4, 0, 0, 0)) # change the margin sizes\nbarplot(islands_df$Area)\n```\n\n::: {.cell-output-display}\n![Island areas with barplot defaults](P1_R_recap_files/figure-pdf/fig-island_1-1.pdf){#fig-island_1 fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\nThe whole dataset includes a lot of very small areas, so let's cut it down to just the 10 largest. Since the dataset is already sorted, we can take rows `1:10`.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbarplot(islands_df$Area[1:10])\n```\n\n::: {.cell-output-display}\n![Top 10 island areas](P1_R_recap_files/figure-pdf/fig-island_2-1.pdf){#fig-island_2 fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\nAnd the next step is to add some names to the x-axis...\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbarplot(islands_df$Area[1:10], names=islands_df$LandMass[1:10])\n```\n\n::: {.cell-output-display}\n![Top 10 island areas with names](P1_R_recap_files/figure-pdf/fig-island_3-1.pdf){#fig-island_3 fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\nWhich of course are unreadable. There are many options here (e.g., see `las` in `?par`) but we will rotate the plot. To do this, we need to re-adjust the margins, set `horiz=TRUE` and `las=1`, and use `[10:1]` so the largest is on top.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mar=c(4, 10, 0, 0))\nbarplot(islands_df$Area[10:1], names=islands_df$LandMass[10:1], \n        horiz=TRUE, las=1, xlab=\"Area (km2)\")\n```\n\n::: {.cell-output-display}\n![Finally! Did you know Antarctica is bigger than Europe?](P1_R_recap_files/figure-pdf/fig-island_4-1.pdf){#fig-island_4 fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\nData visualization is an iterative process with lots of trial and error to find a plot that communicates the message within the data well. There are several packages (e.g., *ggplot2*) that make these sort of adjustments and explorations less opaque than all of the options in `par()`.\n\n::: callout-note\nWe will cover *ggplot2* and other the *tidyverse* packages in more detail soon. You are welcome to use whichever system you prefer.\n:::\n\n------------------------------------------------------------------------\n\n## Summary statistics\n\nYou will often need to summarise your data before you present it. Data summaries are usually contained in tables and they can sometimes replace graphics (e.g., where the data is relatively simple or where individual precise values are important). There are many types of summary statistics. Here we are concerned with central tendency and variability.\n\n::: Q.\nWhat are the three main measures of central tendency?\n:::\n\n::: Q.\nWhat are three measures of variability?\n:::\n\nThe most appropriate metrics of central tendency or variability will depend on your data. Another summary statistic that you might include is sample size. R is very good at producing summary statistics, and there are myriad ways to produce them. We'll return to the `cars2` dataset.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(cars2) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   speed_mph       dist_ft      \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(cars2[cars2$speed_mph > 20, ]) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Recall the options to access a column in a dataframe\nsummary(cars2$speed_mph) \nsummary(cars2[, 1])\nsummary(cars2[, \"speed_mph\"])\n```\n:::\n\n\n\n\n\n\n\n\nOften you'll wish to summarise your data across levels of a certain factor, such as levels of a certain treatment. More complex summaries can be made using the *dplyr* package. We'll go into more detail later on some of the very powerful ways this package (and others in the *tidyverse*) can be used.\n\nWe'll use the built-in dataset `InsectSprays`. Viewing your raw data can be an important check as well. You can open a spreadsheet-style viewer in R using `View(YourDataFrame)`.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(InsectSprays)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t72 obs. of  2 variables:\n $ count: num  10 7 20 14 14 12 10 23 17 20 ...\n $ spray: Factor w/ 6 levels \"A\",\"B\",\"C\",\"D\",..: 1 1 1 1 1 1 1 1 1 1 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(InsectSprays) # glimpse() is loaded with tidyverse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 72\nColumns: 2\n$ count <dbl> 10, 7, 20, 14, 14, 12, 10, 23, 17, 20, 14, 13, 11, 17, 21, 11, 1~\n$ spray <fct> A, A, A, A, A, A, A, A, A, A, A, A, B, B, B, B, B, B, B, B, B, B~\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# spray is the categorical predictor; count is the response\nView(InsectSprays)\n```\n:::\n\n\n\n\n\n\n\n\nTo do more complex summaries, we will string together a series of functions. This can be done in a nested format (e.g., `fun3(fun2(fun1(dataset)))`), but this gets unwieldy very quickly.\n\nSo, let's use the *pipe* operator `|>`. This takes the output from one function and feeds it as the first input of the next (e.g., `dataset |> fun1() |> fun2() |> fun3()`), making code much more legible. Many functions in the *tidyverse* are built for piping.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n?`|>`\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# use group_by() with the grouping column name(s)\nspray_summaries <- InsectSprays |>\n  group_by(spray) |>\n  summarise(count_mean=mean(count))\nspray_summaries\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# it is very easy to calculate any number of summary statistics\nInsectSprays |>\n  group_by(spray) |>\n  summarise(mean=mean(count) |> signif(3),\n            median=median(count),\n            max=max(count),\n            sd=sd(count) |> signif(3),\n            N=n(),\n            N_over_10=sum(count > 10),\n            Pr_over_5=mean(count > 5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 8\n  spray  mean median   max    sd     N N_over_10 Pr_over_5\n  <fct> <dbl>  <dbl> <dbl> <dbl> <int>     <int>     <dbl>\n1 A     14.5    14      23  4.72    12         9    1     \n2 B     15.3    16.5    21  4.27    12        11    1     \n3 C      2.08    1.5     7  1.98    12         0    0.0833\n4 D      4.92    5      12  2.5     12         1    0.167 \n5 E      3.5     3       6  1.73    12         0    0.167 \n6 F     16.7    15      26  6.21    12        10    1     \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n### Choosing a central tendency metric\n\nThe choice of central tendency metric depends on the nature of the data and objectives of your research. We will use datasets that you downloaded from Brightspace (Practicals \\> data). Remember to put these into the *data* folder in your working directory (or modify the file paths in the code accordingly).\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# this will load the 'Scallop %fat' data sheet from the xlsx spreadsheet.\nscallop_df <- read_excel(\"data/H2DS_practicalData.xlsx\", sheet=\"Scallop %fat\")\nstr(scallop_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [49 x 1] (S3: tbl_df/tbl/data.frame)\n $ Scallop % fat: num [1:49] 22.5 24.1 18.2 32.5 17.4 23.6 21.5 22.2 27.6 22.2 ...\n```\n\n\n:::\n\n```{.r .cell-code}\n# avoid spaces and symbols in column names. It's a pain.\nnames(scallop_df) <- \"fat_pct\"\n```\n:::\n\n\n\n\n\n\n\n\n::: Q.\nCheck the data using the methods above. Does it look OK to you?\n:::\n\n::: Q.\nAre these data likely to be continuous or discontinuous?\n:::\n\n::: Q.\nCreate a plot to visualize the distribution of these data.\n:::\n\n::: Q.\nDo you spot any issues?\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## View solution\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(scallop_df$fat_pct, main=NULL) # (what does 'main=NULL' do?)\n```\n\n::: {.cell-output-display}\n![Histogram of fat percentage.](P1_R_recap_files/figure-pdf/fig-scallop_hist-1.pdf){#fig-scallop_hist fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n:::\n\nYou should have spotted a potential outlier. Data entry errors are common, and a check against the original data sheet shows that the decimal was typed in the wrong place. The following code helps you locate the error.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwhich(scallop_df$fat_pct > 50) # which() returns the indexes\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 36\n```\n\n\n:::\n\n```{.r .cell-code}\nscallop_df$fat_pct[35:37] # row 36 is 99.0, but should be 9.90\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 22.8 99.0 12.9\n```\n\n\n:::\n\n```{.r .cell-code}\nscallop_df <- scallop_df[, c(1, 1)] # duplicate column\nnames(scallop_df) <- c(\"fat_pct_orig\", \"fat_pct_corr\")\nhead(scallop_df, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 2\n  fat_pct_orig fat_pct_corr\n         <dbl>        <dbl>\n1         22.5         22.5\n2         24.1         24.1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# there are many ways to 'fix' the outlier in R.\n# You need to correct the outlier in row 36 of column 'fat_pct_corr'\nscallop_df$fat_pct_corr[36] <- 9.9\nwhich(scallop_df$fat_pct_corr > 90) \n# integer(0) - this means that no elements in fat_pct_corr contain values >90\n```\n:::\n\n\n\n\n\n\n\n\nNow summarise `scallop_df` using some of the methods above.\n\n::: Q.\nCreate a histogram for the corrected column. How does it differ from the original column with the error?\n:::\n\n::: Q.\nCalculate mean, variance, median, interquartile range, minimum, maximum and range for both fat_pct_orig and fat_pct_corr.\n:::\n\n::: Q.\nSuppose the outlier was even bigger (i.e. your typo was even worse). Adjust your data, multiplying the erroneous data item by 10; copy the `fat_pct_orig` column and change row 36 to 999.\n:::\n\n::: Q.\nCalculate the same summary statistics.\n:::\n\n::: Q.\nWhich measures of central tendency and variability are most 'robust' against this outlier?\n:::\n\nOr look individually instead of calculating many metrics at once with `dplyr` functions:\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(scallop_df$fat_pct_corr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   8.50   16.90   20.60   19.56   22.50   32.50 \n```\n\n\n:::\n\n```{.r .cell-code}\nvar(scallop_df$fat_pct_corr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 22.79836\n```\n\n\n:::\n\n```{.r .cell-code}\nIQR(scallop_df$fat_pct_corr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.6\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\nR is excellent at generating well formatted tables such as shown in @tbl-scallop. What is missing from from this table?\n\n\n\n\n\n\n\n\n::: {#tbl-scallop .cell tbl-cap='Summary statistics with and without an outlier. Note which summary stats are most influenced by the outlier.'}\n::: {.cell-output-display}\n\n\n|Column       | Mean| Median| Standard deviation| Range| Interquartile range|\n|:------------|----:|------:|------------------:|-----:|-------------------:|\n|fat_pct_corr | 19.6|   20.6|               4.77|  24.0|                 5.6|\n|fat_pct_orig | 21.4|   20.6|              12.20|  90.5|                 5.3|\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n::: Q.\nHow would the patterns seen in @tbl-scallop influence your choice if you were required to summarise data that you thought might contain values that could be erroneous? Consider how each metric is influenced by the data distribution and by outliers.\n:::\n\nLet's load a dataset that gives the length of hake across three years of sampling.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhake_df <- read_excel(\"data/H2DS_practicalData.xlsx\", sheet=\"Hake\")\nstr(hake_df) # once again, column names made for excel rather than R\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [499 x 2] (S3: tbl_df/tbl/data.frame)\n $ Year            : num [1:499] 1 1 1 1 1 1 1 1 1 1 ...\n $ Hake length (mm): num [1:499] 190 219 181 148 206 204 168 197 178 211 ...\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n::: Q.\nWhat type of variable is `length`?\n:::\n\n::: Q.\nSelect an appropriate graphical method and display these data.\n:::\n\n::: Q.\nIn your own time, use the `dplyr` functions to summarise the hake data by year.\n:::\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhake_df$Year <- as.factor(hake_df$Year) # Treat as categorical, not numeric\nnames(hake_df) <- c(\"Year\", \"Length\") # simplify the column names\n```\n:::\n\n::: {#tbl-hake .cell tbl-cap='Summary of hake data.'}\n::: {.cell-output-display}\n\n\n|Year | Mean length (cm)|\n|:----|----------------:|\n|1    |            201.8|\n|2    |            497.0|\n|3    |            988.9|\n\n\n:::\n:::\n\n\n\n\n\n\n\n\nThe following 'settling velocity' data relates to the settling velocity of salmon faecal material. Shona Magill generated these data.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishPoo_df <- read_excel(\"data/H2DS_practicalData.xlsx\", sheet=\"Settling velocity\")\nstr(fishPoo_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [200 x 1] (S3: tbl_df/tbl/data.frame)\n $ Settling velocity (mm s-1): num [1:200] 2.06 1.03 1.56 1.88 1.16 0.76 1.26 1.13 1.23 1.31 ...\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n::: Q.\nProduce a histogram of the settling velocity. Is it left or right skewed?\n:::\n\n::: Q.\nWhich measures of central tendency and variability are most appropriate?\n:::\n\n::: Q.\nSketch the distribution and indicate the relative positions of the mean and median.\n:::\n\n::: Q.\nGenerate a new column of the log-transformed settling velocity data and plot these data.\n:::\n\n::: Q.\nWhat measures of central tendency and variability could be applied to the log-transformed data? Selecting the preferable metrics for a dataset is not necessarily straightforward.\n:::\n\n@tbl-metric gives some indication of what issues you might consider.\n\n\n\n\n\n\n\n\n::: {#tbl-metric .cell tbl-cap='Appropriate measures of central tendency and variability according to the underlying data distribution.'}\n::: {.cell-output-display}\n\n\n|Data distribution               |Central tendency metric |Variability metric       |\n|:-------------------------------|:-----------------------|:------------------------|\n|Continuous, unimodal, symmetric |Mean                    |Variance or sd           |\n|Continuous, skewed              |Median                  |Interquartile range      |\n|Continuous, multimodal          |None; state modes       |None; summarise by group |\n|Discontinuous                   |None; data-dependent    |Range?                   |\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n## Conclusions\n\nVisualizing and summarising data are the critical first steps in the data analysis and reporting workflow. We use graphical methods to firstly explore our own data. Once we have made sense of it we select the most appropriate method to convey that understanding to our readers. We may help that communication by summarising data in the most appropriate way taking into account the distribution of the data and the presence of outliers.\n",
    "supporting": [
      "P1_R_recap_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}